---
layout: post
title:  "以频域的方式思考"
date:   2019-04-15 16:11:07 +0800
categories: cv
---


 <script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script> 

首先复习，原图是f，新图是h，滤波器是g
滤波器操作实际上是：
$$
h[m, n]=\sum_{k, l} g[k, l] f[m+k, n+l]
$$

<!-- more -->
图像滤波在空间域上的变换。

现在要学的是在频域上的滤波，以频域的观点看滤波。采样。
为什么高斯滤波有很光滑的图像，但是箱子滤波器有像边缘一样的东西呢？

混合图像，为什么能够得到不同的，和距离相关的解释interpretations混合图像呢？

为什么小分辨率的图像仍然给我们和大图一样的感觉呢？什么信息被丢失了？

傅里叶疯狂的想法：任何单值univariate函数都可以写成一系列加权的，不同频率的sin函数的和。

sin函数的和：
$$
A \sin (\omega x+\phi)
$$

频率谱：比如
$$
g(t)=\sin (2 \pi f t)+(1 / 3) \sin (2 \pi(3 f) t)
$$

![频率](/assets/cv/freq.png)

方波函数也能够展开，方波能够写成无穷级数。

$$
A \sum_{k=1}^{\infty} \frac{1}{k} \sin (2 \pi k t)
$$

音乐也可以进行频率分析。
图形可以做快速傅里叶变换。

下面的代码虽然没有出现和ppt那样的效果，但是大致趋势是差不多的。

{% codeblock lang:python %}
w =256
img = np.zeros((w,w))
img[w//2, w//2] = 255
img[w//2, w//2 + 2 ] = 255
img[w//2, w//2 - 2 ] = 255
img2 = np.fft.fft2(img)
img2 = img2.astype(np.uint8)
print(img2)
new_img = np.fft.fftshift(img2)
cv2.imshow('origin',img)
cv2.imshow('test',img2)
cv2.imshow('shift',new_img)
cv2.waitKey()
{% endcodeblock %}

原本的图：
![频率](/assets/cv/fourier_1.png)

信号能够叠加：
![频率](/assets/cv/fourier_2.png)

这是处理的一张图：
![处理的猫](/assets/cv/cat_1.jpg)

经过fft之后，这个图变成了这样：

暂时没有，等我去做一下作业qwq

傅里叶变换存储着每个频率的幅值和相位
- 幅值记录了信号的强度
- 相位记录了空间信息（不直接）
- 为了数学的便利，经常使用实数和复数来表示。

幅值： 
$$
A=\pm \sqrt{R(\omega)^{2}+I(\omega)^{2}}
$$

相位：
$$
\phi=\tan ^{-1} \frac{I(\omega)}{R(\omega)}
$$

欧拉公式：
$$
e^{i n x}=\cos (n x)+i \sin (n x)
$$

计算傅里叶变换：

$$
H(\omega)=\mathcal{F}\{h(x)\}=A e^{j \phi}
$$

连续：
$$
H(\omega)=\int_{-\infty}^{\infty} h(x) e^{-j \omega x} d x
$$

离散：
$$
H(k)=\frac{1}{N} \sum_{x=0}^{N-1} h(x) e^{-j \frac{2 \pi k x}{N}} \quad k=-N 2 \ldots N / 2
$$

卷积定理：
两个信号的卷积的傅里叶变换，等于他们傅里叶变换的乘积

两个信号的乘积的逆傅里叶变换是两个逆傅里叶变换的卷积。

实数信号的傅里叶变换关于原点对称。

时域和频域当中能量相同。Parseval定理。

微分使得信号高频部分线性放大。

时域当中的卷积是频域当中的乘积。

傅里叶变换使用matlab来表示。

```matlab
im = imread('cat_1.jpg');
im = rgb2gray(im);
[imh, imw]=size(im);
fftsize =1024;
im_fft = fft2(im,fftsize,fftsize);
hs=50;
fil = fspecial('gaussian',hs*2+1,10);
fil_fft = fft2(fil,fftsize,fftsize);
im_fil_fft = im_fft .* fil_fft;
im_fil = ifft2(im_fil_fft);
im_fil = im_fil(1+hs:size(im,1)+hs, 1+hs:size(im,2)+hs);

figure(1);
img2 = log(abs(fftshift(fil)));
imagesc(img2)
axis image
% colormap jet
```

经过艰苦卓绝的斗争，终于写出了Python版本= =。在图上画的其实是log(abs())后的图。
fftshift就是把四个方块调整下顺序，并且由于实信号是对称的，也就无所谓了。

现在还没有写高斯核的卷积。

{% codeblock lang:python %}
img = cv2.imread('cat_1.jpg',0)
img2 = np.fft.fft2(img)
img2 = np.log(np.abs(img2))
new_img = np.fft.fftshift(img2)
new_img = (new_img - np.min(new_img))/(np.max(new_img) - np.min(new_img)) * 255
print(new_img)
new_img = new_img.astype(np.uint8)
new_img = cv2.applyColorMap(new_img,cv2.COLORMAP_JET)
cv2.imshow('shift',new_img)
cv2.waitKey()
{% endcodeblock %}

{% codeblock lang:python %}
def normal_distribution(x, mean, sigma):
    return np.exp(-1*((x-mean)**2)/(2*(sigma**2)))/(np.sqrt(2*np.pi) * sigma)
 

if __name__ == "__main__":
    img = cv2.imread('cat_1.jpg',0)
    w,h = img.shape
    img2_o = np.fft.fft2(img)
    img2 = np.log(np.abs(img2_o))
    new_img = np.fft.fftshift(img2)

    mean, sigma,num_x, num_y = 0,100,w,h

    gaussian_x = normal_distribution(np.linspace(mean - 3*sigma**2,mean+3*sigma**2,w),mean,sigma)
    gaussian_y = normal_distribution(np.linspace(mean - 3*sigma**2,mean+3*sigma**2,h),mean,sigma)

    kernel = np.matmul(gaussian_x[:,None],gaussian_y[None,:])
    print(kernel.shape)
    kernel_fft = np.fft.fft2(kernel)

    res_img = kernel_fft * img2_o
    res_res = np.fft.ifft2(res_img)
    res_res = np.fft.fftshift(res_res)
    res_res = (res_res - np.min(res_res))/(np.max(res_res) - np.min(res_res)) * 255
    res_res = res_res.astype(np.uint8)
    print(res_res)

    new_img = (new_img - np.min(new_img))/(np.max(new_img) - np.min(new_img)) * 255
    new_img = new_img.astype(np.uint8)
    new_img = cv2.applyColorMap(new_img,cv2.COLORMAP_JET)
    cv2.imshow('shift',new_img)
    cv2.imshow('res',abs(res_res))
    cv2.waitKey()
{% endcodeblock %}

问题：
1. 是相位还是幅值含有更多信息呢？
    幅值包含低频信息，大部分集中在中间，相位信息是高频信息。
2. 如果把一个图的相位和另一张图的幅值结合起来，会变成什么样子？
    这个自己做太麻烦了，我从网上找了个例子：
    
    实际运行的代码如下：

    ```matlab
    %%图像的傅里叶变换%%
    imA=imread('cat_1.jpg'); %读取图像
    imB=imread('lenna.jpg');
    imA = rgb2gray(imA);
    imA = imresize(imA,[256,256]);
    imB = rgb2gray(imB);
    subplot(2,3,1);
    imshow(imA);
    title('原图像A');
    subplot(2,3,2);
    imshow(imB);
    title('原图像B');
    FA=fft2(imA);%对图像进行傅里叶变换
    FB=fft2(imB);
    fA=fftshift(FA); %对图像频谱进行移动，是0频率点在中心
    fB=fftshift(FB);
    sA=log(abs(fA));%获得傅里叶变换的幅度谱
    sB=log(abs(fB));
    phA=log(angle(fA)*180/pi);%获得傅里叶变换的相位谱
    phB=log(angle(fB)*180/pi);
    A_new = abs(fA).*cos(angle(fB)) + sin(angle(fB)).*abs(fA) *1j;
    B_new = abs(fB).*cos(angle(fA)) + sin(angle(fA)).*abs(fB) *1j;
    subplot(2,3,3);
    imshow(sA,[]); %显示图像的度谱，参数与[]是为了将sA的值线形拉伸
    title('图像A的傅里叶变换幅度谱');
    subplot(2,3,4);
    imshow(phA,[]); %显示图像傅里叶变换的相位谱
    title('图像A傅里叶变换的相位谱');
    subplot(2,3,5);
    imshow(sB,[])
    title('图像B的傅里叶变换幅度谱');
    subplot(2,3,6);
    imshow(phB,[]);
    title('图像B傅里叶变换的相位谱');
    % A=ifft2(FA);%傅里叶反变换
    % B=ifft2(FB);
    A = ifft2(A_new);
    B = ifft2(B_new);
    figure
    subplot(1,2,1);
    imshow(A,[]);
    title('傅里叶反变换得到的A图像');
    subplot(1,2,2);
    imshow(B,[]);
    title('傅里叶反变换的到的B图像');
    ```

    ![交换的过程](/assets/cv/experience.png)

    图中可以看出经过交换相位谱和反变换后得到的图像内容与其相位谱对应的图像一致。

    从图上可以看出，相位还是能够让我们看到轮廓的。

图像的平移并不会影响图像的频谱，同时，图像的相位会随着图像的旋转而旋转。

如果只保留图像的中心点，则图像的细节会丢失，大致轮廓还在，不同区域有不同的灰度。

如果保留远离中心的点，而去掉中心的幅度，则保留着图像的细节，而不同区域的灰度一样。

傅里叶变换后的白色部分（即幅度较大的低频部分），表示的是图像中慢变化的特性，或者说是灰度变化缓慢的特性（低频部分）。

傅里叶变换后的黑色部分（即幅度低的高频部分），表示图像中快变化的特性，或者说是灰度变化快的特性（高频部分）。

为什么高斯效果比箱子好呢？

问题1：匹配下面的图片和傅里叶变换。（wc这个真的难qwq）

低分辨率图片，我们仍然能够判断出图片当中描述的是啥，为什么？我们损失了什么？

每隔一个像素扔一个像素，下采样这样。

采样问题aliasing problem。

下采样是危险的，比如说车轮子在电影里面看的时候是向相反方向在运动。棋盘在光线追踪中瓦解，条纹的衣服在电视当中的颜色很奇怪。

想象一个辐条的轮子向右移动（顺时针转），在轮子上标一个点，这样我们就能卡岸大奥发生什么事情了。

如果相机快门只在一帧的时间拍的话。

但是如果没有点的话，我们看到这个轮子在倒着走。

还有崩掉的棋盘纹理，离得特别远的地方，白色就连成一片了。
![chessboard](/assets/cv/chessboard.png)

采样和混叠：如果一个垃圾滤波器：比如说方框形滤波器下采样一个信号的话，来处理一个高频线性调频脉冲(chirp)图像。

复习一下香农采样定理：

从样本中重建吸纳好的最小采样频率必须至少是最高频率的两倍。信号当中频率最高的频率是奈奎斯特频率，最小采样频率的倒数为奈奎斯特率。

抗混叠的解决办法：
- 多采样呗。
- 丢掉所有高于新采样频率一半以上的所有信号。但是这样会：
    - 丢失信息
    - 更抗混叠
    - 意思就是用了一个平滑滤波器。

下采样1/2的方法：
- 从图像(h,w)开始
- 执行低通滤波器。
    - `im_blur = imfilter(image,fspecial('gaussian', 7,1))`
- 每隔一个信号采样一次。
    - `im_small = im_blur(1:2:end,1:2:end)`

给一个图片的例子：

![chessboard](/assets/cv/anti_aliasing.png)

如果不提前滤波的话，很难看，就像这样：
![van](/assets/cv/van.png)

提前滤波的话就好一点：
![van](/assets/cv/van2.png)

所以低分辨率的图片损失了高频信息，留下了低频信息。

依赖于距离的插值混合图像。

人的感受：
- 早期人类滤波器改变朝向和频率的尺度
- 人类对感中高频信号感受最敏感
- 当我们从远处看到一张图的时候，已经下采样掉了。

混合图像其实就是A图的低通滤波+B图的高通滤波。

要记住的事情
- 傅里叶分析有时候很有用，转化到频域当中考虑问题
- 使用快速傅里叶变换，能够在NlogN的时间计算出来
- 图像被平滑了（基本压缩）
- 记住在采样之前先低通滤波。