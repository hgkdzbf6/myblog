---
title: 9了都，拟合和对齐
date: '2019-04-20 11:22:33 +0800'
categories: cv
tags: cv
---

 <script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script> 

## 拟合和对齐

拟合：找到最适合数据的模型参数
对齐：找到最佳对齐匹配点的转换参数

## 拟合和对齐的方法：

1. 全局优化来找参数
  - 最小二乘
  - 鲁棒最小二乘
  - 迭代最近点（Iterative closest point, ICP）
2. 假设和测试
  - 广义霍夫变换
  - RANSAC

## 如何拟合一条直线？
<!-- more -->
数据: 

$$
\left(x_{1}, y_{1}\right), \ldots,\left(x_{n}, y_{n}\right)
$$

直线方程：

$$
y_{i}=m x_{i}+b
$$

找到一组m,b，使得下面的参数最小化：

$$
E=\sum_{i=1}^{n}\left(y_{i}-m x_{i}-b\right)^{2}
$$

$$
E=\sum_{i=1}^{n}\left(\left[ \begin{array}{ll}{x_{i}} & {1}\end{array}\right] \left[ \begin{array}{l}{m} \\ {b}\end{array}\right]-y_{i}\right)^{2}
=\left[ \begin{array}{cc}{x_{1}} & {1} \\ {\vdots} & {\vdots} \\ {x_{n}} & {1}\end{array}\right] \left[ \begin{array}{l}{m} \\ {b}\end{array}\right]-\left[ \begin{array}{c}{y_{1}} \\ {\vdots} \\ {y_{n}}\end{array}\right]^{2}=\|\mathbf{A} \mathbf{p}-\mathbf{y}\|^{2}
$$

$$
=\mathbf{y}^{T} \mathbf{y}-2(\mathbf{A} \mathbf{p})^{T} \mathbf{y}+(\mathbf{A} \mathbf{p})^{T}(\mathbf{A} \mathbf{p})
$$

$$
\frac{d E}{d p}=2 \mathbf{A}^{T} \mathbf{A} \mathbf{p}-2 \mathbf{A}^{T} \mathbf{y}=0
$$

$$
\mathbf{A}^{T} \mathbf{A} \mathbf{p}=\mathbf{A}^{T} \mathbf{y} \Rightarrow \mathbf{p}=\left(\mathbf{A}^{T} \mathbf{A}\right)^{-1} \mathbf{A}^{T} \mathbf{y}
$$

但是这个是垂直的最小二乘，每个误差计算的时候是算距离，而不是距离直线的距离。像这张图一样：

![这张图](/assets/cv/line_fit.png)

而且，对于完全垂直的线就没办法了qwq。

total least squares：总最小二乘法

如果
$$
a^{2}+b^{2}=1
$$
的话，那么点$(x_i,y_i)$到直线$ax+by+c=0$之间的距离就是：$\vert ax_i + b y_i + c \vert$。

这次约束就变成了使得距离的平方和最小，三个参数待估计，以及一个约束条件
$$
a^{2}+b^{2}=1
E=\sum_{i=1}^{n}\left(a x_{i}+b y_{i}+c\right)^{2}
$$

$$
\frac{\partial E}{\partial c}=\sum_{i=1}^{n} 2\left(a x_{i}+b y_{i}+c\right)=0
$$

$$
c=-\frac{a}{n} \sum_{i=1}^{n} x_{i}-\frac{b}{n} \sum_{i=1}^{n} y_{i}=-a \overline{x}-b \overline{y}
$$

$$
E=\sum_{i=1}^{n}\left(a\left(x_{i}-\overline{x}\right)+b\left(y_{i}-\overline{y}\right)\right)^{2}
=\mathbf{p}^{T} \mathbf{A}^{T} \mathbf{A} \mathbf{p}
$$

$$
\text { minimize } \mathbf{p}^{T} \mathbf{A}^{T} \mathbf{A} \mathbf{p} \quad \text { s.t. } \mathbf{p}^{T} \mathbf{p}=1
\Rightarrow \quad \text { minimize } \frac{\mathbf{p}^{T} \mathbf{A}^{T} \mathbf{A} \mathbf{p}}{\mathbf{p}^{T} \mathbf{p}}
$$

最小二乘解：

$$
\mathbf{x}=\left(\mathbf{A}^{T} \mathbf{A}\right)^{-1} \mathbf{A}^{T} \mathbf{b}
$$

total最小二乘解：
$$
[\mathbf{v}, \lambda]=\operatorname{eig}\left(\mathbf{A}^{T} \mathbf{A}\right)
$$
x是最小特征值对应的特征向量。

全局最小二乘优化：
优点
- 清晰明确的目标函数
- 优化很简单

缺点
- 可能不是你想要优化的
- 对错误值敏感
- 不允许你得到多个好的拟合结果。

鲁棒最小二乘：为了处理outliers。
一般方法说明：其实就是最小化这个东西
$$
\sum_{\mathrm{i}} \rho\left(\mathrm{u}_{\mathrm{i}}\left(\mathrm{x}_{\mathrm{i}}, \theta\right) ; \sigma\right)
$$

w.r.t.参考。
$u_{i}\left(x_{i}, \theta\right)$，第i个点的关于模型参数θ的剩余。
ρ：鲁棒函数
1. 支持具有小残差的配置。
2. 对于大的残差，使用常数惩罚项。

如果是使用平方的话，对于偏差很大的话，对最后结果的影响很大。

鲁棒估计：
1. 初始化：选择θ，使用最小二乘拟合，σ=1.5*误差的中位数
2. 选择一个参数去最小化：
  $$
  \sum_{i} \frac{\operatorname{error}\left(\theta, d a t a_{i}\right)^{2}}{\sigma^{2}+\operatorname{error}\left(\theta, d a t a_{i}\right)^{2}}
  $$
  也就是数值优化
3. 计算新的sigma为σ=1.5*误差的中位数
4. 重复2和3步骤，直到收敛

其他找到参数的方法(对于没有解析解的情况下)：
1. 线性搜索
  - 对于每个参数，遍历每个值，选择最好的值去拟合
  - 重复上面的步骤，知道没有什么参数变化了
2. 网格搜索
  - 提出几组参数，在关节集中均匀采样
  - 选择最佳（或前几个）并围绕当前最佳样本联合参数; 重复
3. 梯度下降
  - 提供初始位置（比如随机）
  - 根据参数，局部搜索更好的参数

假设和测试
1. 首先提出参数
  - 测试所有的可能性
  - 每个点对所有不变的参数投票
  - 重复采样足够的点去解决这个问题
2. 对给定的参数打分
  - 一致点数，可能按距离加权
3. 从参数集合当中进行选择
  - 本地和局部最大化这个分数
4. 使用内点来精炼参数

Hough变换：外点
1. 创建一个网格参数值
2. 每个点对一个参数集合投票，增加这些网格中的值
3. 找到网格中最大或者局部最大的点

给出一个点的集合，找到曲线或者直线，能够最好的解释这一些点。
比如y=mx+b
但是这个参数空间是没有边界的。
所以使用极坐标表示这个参数空间：
xcosθ+ysinθ=ρ

拟合实验：
- 如果就正好是一条直线的话，没啥好说的。
- 如果是拟合直线的话，在交点处划分网格，选择线的数量最多的点作为这个霍夫变换的点。
- 如果没啥关机，也就没啥有用的信息了

图像当中找直线的办法：
1. 图像先转化成Canny（找边缘）
2. 边缘的点，然后Hough投票
3. 找到极值点，然后处理

对于图中，直线很多的情况的话，交点会很好看的qwq。

拟合圆的方法：
1. 固定r
2. r是变量

霍夫变换：
- 好处：
  - 对于outliers是鲁棒的：每个点都分别投票
  - 相当高效（比测试所有的参数快多了）
  - 提供多个好的拟合

- 缺点：
  - 对噪声有点敏感
  - 需要对bin大小（也就是网格大小），和噪声容忍度，精度，时间，内存进行权衡
  - 找到最佳点太难了
  - 对更多的参数就不咋适应了（比如拟合一个倾斜的椭圆，有5个参数qwq）

- 应用场景
  - 直线拟合：（圆形，椭圆拟合）
  - 物体实例检测（参数是位置，尺度，朝向）
  - 物体类别检测（参数是位置，尺度）
广义霍夫变换，参考[这里](https://github.com/vmonaco/general-hough/blob/master/src/GeneralHough.py)

RANSAC (Random Sample Consensus)
- Sample，随机采样一些点，能够拟合出一个模型
- Solve，把每一个点带进模型里面去。给出一个阈值，在阈值之内就是符合这个模型
- Score，通过模型的预设阈值内的分数的分数进行评分
- Repeat，重复上面三步，直到找到最好的参数。

如何选择参数？
1. 采样点数量N
  - 选择N，使得以概率p，至少一个随机采样的结果是没有异常值的（也就是p=0.99），异常值的比例：e
2. 采样点的数量s
  - 拟合出这个结果所需要的最少的采样点数量
3. 距离的门限值δ
  - 选择δ，使得一个有噪声的好的点在门限里面（比如prob=0.95）
  - 零均值高斯噪声，标准差为t^2=3.84σ^2
选择的公式：
$$
\mathrm{N}=\log (1-\mathrm{p}) / \log \left(1-(1-\mathrm{e})^{\mathrm{s}}\right)
$$

结论：
- 优点：
  - 对outliers鲁棒
  - 适用于比Hough变换更多的目标函数参数
  - 优化参数比Hough变换更容易选择

- 缺点：
  - 随着outliers的比例和参数数量的增多，计算时间增长很快。
  - 对于获得多个匹配不怎么好（虽然得到一个解之后，再把这个解去掉，然后重复做匹配能解决这个问题）

- 应用：
  - 计算单应性（比如图像拼接）
  - 估计本质矩阵（两个视图进行关联）

如果你想要对齐，但是没有主要的匹配对怎么办?
霍夫变换和RANSAC方法不能用了qwq。
但是很有用，比如说脑CT，（zxp的项目）

迭代最近点算法。
目标：估计两组密集点之间的变换
1. 初始化转换（例如，计算均值和比例的差异）
2. 对于在集合1中的每个点，分配到在集合2里面最近的邻居上。
3. 估计变换参数，例如，最小二乘法或鲁棒最小二乘法
4. 使用估计的参数把集合1变换到集合1'。再用集合2和集合1'。
5. 再用集合2和集合1'比较更改。如果非常小退出，否则继续步骤2-4

算法总结：
1. 最小二乘拟合：有闭合解，对噪声鲁棒，对outliers不鲁棒
2. 鲁棒最小二乘：改进了对噪声的鲁棒。需要迭代优化，
3. Hough变换：对于噪声和outliers鲁棒，可以拟合出多个模型（同时找到多个直线）。只需要决定很少的参数（1-4个）
4. RANSAC：对噪声和outlier鲁棒，参数中等（1-8个）
5. 迭代最近点ICP，对于本地对齐来说最好，不需要初始的响应。

举个例子，已知两张图上的两个点集合，如何求得这个平移？
- 最小二乘
  1. 写出目标函数
  2. 计算偏差，计算解
  3. 计算解，以$Ax=b$的形式，使用伪逆，或者特征值分解来求解。

- RANSAC解，解决的问题是ourliers
  1. 随机采样一对匹配点
  2. 使用变换的参数来求解
  3. 为每个参数进行打分
  4. 重复1-3步

- Hough变换，解决的问题是：outliers，多个物体，或者多对一匹配
  1. 初始化网格参数
  2. 每个匹配对，对应于一个投票，对于一致的值来说
  3. 找到对应投票最多的参数
  4. 对inliers解最小二乘问题

- ICP解，解决的问题是：不需要对初始响应做什么猜测
  1. 找到每个点的最近点
  2. 通过匹配计算位移
  3. 按照这个位移移动图1中的点
  4. 重复1-3步直到收敛

下一节：物体检测。