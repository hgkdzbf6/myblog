---
title: '模板,图像金字塔和滤波器堆积'
date: 2019-04-16 12:52:20 +0800
categories: cv
tags: cv
---

 <script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script> 

## 复习：已经学习了

- 时域的滤波器
- 频域的滤波器
- 偏移后的中心为低频段，外面是高频段，边缘响应一般都比较强，所以中心的很厉害。对角频率有的时候也很大。

## 今天课程：

- 模板匹配
- 图像金字塔
- 滤波器堆积和纹理
- 去噪，压缩

如何给出眼睛的图片，找到爱因斯坦的眼睛？

两个块之间，衡量相似程度的方法，或者差距？
- 协方差
- 零均值协方差
- 偏差的平方和
- 归一化协方差

<!-- more -->
首先我们用滤波器的方法来找：

$$
h[m, n]=\sum_{k, l} g[k, l] f[m+k, n+l]
$$

但是这样是不对的，我们应该先减去模板的平均值，然后再去计算才对。

$$
h[m, n]=\sum_{k, l}(g[k, l]-\overline{g}) (f[m+k, n+l])
$$

好先试验一下。

这个是原图：
![原图](/assets/cv/Einstein.png)

这个是模板
![模板](/assets/cv/eye.png)

处理之后的结果是这样的：

代码如下：

{% codeblock lang:python %}
temp = cv2.imread('eye.png',0)
img = cv2.imread('Einstein.png',0)
temp = temp.astype(np.float32)
img = img.astype(np.float32)
w,h = img.shape
new_img = ss.correlate(img,temp,mode='same')
new_img =  (new_img - np.min(new_img)) / (np.max(new_img) - np.min(new_img)) * 255
new_img = new_img.astype(np.uint8)
print(new_img)
cv2.imshow('img',img)
cv2.imshow('temp',temp)
cv2.imshow('new_img',new_img)
cv2.imwrite('new_img.png',new_img)
cv2.waitKey()
{% endcodeblock %}

记得要导入`scipy`这个包。

然后处理的结果是:
![这样](/assets/cv/new_img.png)

emmmmm...这个和ppt上面的不咋一样虽然，因为我做了很多处理，所以和他处理之后的结果差不多是不是hhhh。

这次我先减去均值试试。
代码上只需要这样：
`temp = temp - np.mean(temp)`
![这样](/assets/cv/new_img2.png)

嗯，和ppt上面一致，眼睛的位置确实变亮了。但是引入了其他白的部分，怎么办？

第二种方法：SSD：平方和。这次不需要减去均值。

卧槽这怎么用numpy写qwq。

先用笨办法写吧qwq。

{% codeblock lang:python %}
def ssd(img,temp):
    w,h = img.shape
    ww,hh = temp.shape
    res = np.zeros_like(img)
    ww2 = ww//2
    hh2 = hh//2
    padding_img = np.zeros((w+ww,h+hh))
    print(ww2,hh2)
    padding_img[ww2:-ww2,hh2:-hh2] = img
    for i in range(w):
        for j in range(h):
            res[i,j] = np.sum(( padding_img[i:i+ww,j:j+hh] - temp)**2)
    return res
{% endcodeblock %}

可以明显感觉到这个运行速度真的慢了很多qwq。

然后这个是结果：

![这样](/assets/cv/new_img3.png)

误差越小的话，这个值越小，所以最后表示图的时候需要用255减去原图，才能和原来表示相同的意思。

但是不能用，比如说亮度稍微变了一点点，像这样：

![这样](/assets/cv/Einstein2.png)

的话，就会变成这样

![这样](/assets/cv/new_img4.png)

所以就用归一化的互相关来表示。公式如下：

$$
h[m, n]=\frac{\sum_{k, l}(g[k, l]-\overline{g})\left(f[m+k, n+l]-\overline{f}_{m, n}\right)}{\left(\sum_{k, l}(g[k, l]-\overline{g})^{2} \sum_{k, l}\left(f[m+k, n+l]-\overline{f}_{m, n}\right)^{2}\right)^{0.5}}
$$

好的，我们现在来实现一下。
这个应该比较快一点，因为没有乘法。（并不是qwq）

{% codeblock lang:python %}
temp = cv2.imread('eye.png',0)
img = cv2.imread('Einstein.png',0)
temp = temp.astype(np.float64)
img = img.astype(np.float64)

normal_img = img - np.mean(img)
normal_temp = temp - np.mean(temp)

zero_temp = np.zeros_like(temp)

one = sn.correlate(normal_img,normal_temp)
two = np.sqrt(ssd(normal_img,zero_temp))
three = np.sqrt(np.sum(normal_temp**2))
new_img = one/two/three
new_img = (new_img - np.min(new_img))/(np.max(new_img) - np.min(new_img)) * 255
new_img = new_img.astype(np.uint8)
print(new_img)
cv2.imshow('img',img)
cv2.imshow('temp',temp)
cv2.imshow('new_img',new_img)
cv2.imwrite('new_img.png',new_img)
cv2.waitKey()
{% endcodeblock %}

对没有加上墨镜的图像是这样子的：

![这样](/assets/cv/new_img5.png)

对加上了墨镜之后，图像是这个样子：

![这样](/assets/cv/new_img6.png)

说明：这里用到了`scipy.ndimage`这个库，功能还是挺多的qwq。卷积，互相关啥的都有，小波也有。

三种方式的比较：

1. 零均值滤波器：最快不好，会误报
2. SSD，不怎么快，对所有的敏感。
3. 归一化协方差，最慢，对本地平均亮度变化和对比度的变化不敏感。

如何找到更大或者更小的眼睛呢？

图像金字塔咯。

图像 -> 经过高斯滤波器 -> 变成低通的图像 -> 采样 -> 低分辨率的图像。

所以就有高斯金字塔。

匹配的步骤：

输入是图像和模板：
1. 用当前模板和当前尺度进行匹配
2. 对图像下采样，一般尺度在1.1到1.2之间
3. 重复1和2步，直到图像非常小
4. 在这些尺度上进行相应，可能需要非极大值抑制。

有拉普拉斯滤波器：单位脉冲减去高斯滤波就是拉普拉斯滤波器了。

如何创建高斯-拉普拉斯金字塔？
图像是G1，
图像G1平滑之后下采样，得到G2
图像G1减去上采样之后的G2，得到L1

图像G2平滑之后下采样，得到G3
图像G2减去上采样之后的G3，得到L2

等等等等等等等

注意：
- 上面的平滑步骤使用相同的滤波器，比如sigma=2
- 下采样或者上采样的时候使用最近邻插值的方法。

高频率到低频率的变化：
![这样](/assets/cv/high_low.png)

同样也可以进行重构：

用拉普拉斯金字塔进行图像重构
G1 = L1 + G2
G2 = L2 + G3
G3 = L3 + G4
G4 = L4

主要用图像金字塔来：
- 压缩
- 物体检测，多尺度范围上，或者搜索特征
- 检测稳定的特征点
- 从粗到精的配准

配准：
1. 计算高斯金字塔
2. 对齐粗的金字塔
3. 连续对齐更精细的金字塔。找更小的范围

为什么快？
这样能够保证得到相同的结果吗？

图像的表示：
- 像素：在时间域上表示很好，但是很难在频域上看出什么来
- 傅里叶变换：频域表示，但是没有空间信息
- 金字塔，滤波器序列：在时间和空间上都有一个平衡。

比如纹理的表示。
- 纹理和材质的关系
- 纹理和朝向的关系
- 纹理和尺度的关系

什么是纹理？有规律的或者随机的模式，由于凸起，凹痕或者标记点。

如何表示纹理？
- 计算斑点和边缘，在不同的尺度和朝向上的响应。

完备overcomplete的表示：filter bank。
LM filter bank。

Filter bank：用bank里的每个滤波器来处理图像，保持响应（或者平方，或者绝对值）

表示纹理的方法：
想法1：记录每个滤波器的简单统计信息，比如均值，方差，或者滤波器的相应的绝对值。

比如你能够看到滤波器，匹配出相应的纹理吗？

![这样](/assets/cv/texture.png)

这个是答案，没想到吧

![这样](/assets/cv/texture_res.png)

想法2：拿滤波器向量，对每个像素进行相应，然后聚集起来，看他的直方图，这个会在几周之内讲到。

压缩：12M图像怎么能够压缩到400K，并且没什么显著的变化？

有损图片压缩：JPEG

分块的离散余弦变换Block-based Discrete Cosine Transform。

第一个系数是B(0,0)，这个是直流分量，也就是平均强度。

最上角的系数表示低频分量，右下角是高频分量。

量化：
- 对高频分量更粗糙，也就是说趋向是更小的值。
- 很多量化的高频值都是0
编码：
- 使用逆DCT来编码。

JPEG压缩：
1. 把图像转化成YCrCb
2. 下采样颜色，比例为2（因为人类对颜色的分辨率不敏感）
3. 分成方块，一般是8*8的方块，然后减去128
4. 对每个方块：
  - 计算离散余弦变换的系数
  - 粗糙量化（很多高频分量都成了0了）
  - 编码（比如说哈夫曼编码）

无损压缩（PNG）
1. 基于最上角的邻居来，预测像素值。
2. 存储预测值和实际值的差
3. Pkzip算法，deflate放气算法

去噪：加性的高斯噪声。

如果sigma太低的话，就没有平滑，如果sigma太高的话更模糊。

标准差越大的话，更平滑也更模糊qwq。

也能降低椒盐噪点，但是降低的程度不大。

另外的想法：中值滤波器。

去一个窗口当中的中位数作为当前值。
中值滤波不是线性的吧qwq。

中值滤波对outlier是鲁棒的，去掉椒盐噪点非常好。

其他非线性滤波器：

加权中值滤波：离中心越远的话权重越小。

剪切的均值滤波：（均值，去掉一个最高分，去掉一个最低分）

双边滤波：根据空间距离和亮度差异来进行权重分配。

双边滤波能够很好的把边缘保留下来，只会加权更相似的像素。

$$
I_{\mathbf{p}}^{\mathrm{b}}=\frac{1}{W_{\mathbf{p}}^{\mathrm{b}}} \sum_{\mathbf{q} \in \mathcal{S}} G_{\sigma_{\mathrm{s}}}(\|\mathbf{p}-\mathbf{q}\|) G_{\sigma_{\mathrm{r}}}\left(\left|I_{\mathrm{p}}-I_{\mathbf{q}}\right|\right) I_{\mathbf{q}}
$$

$p-q$这个是空间的差异。
$G_{\sigma_r}(I_p-I_q)I_q$这个是相似性
$$

$$
W_{\mathrm{p}}^{\mathrm{b}}=\sum_{\mathrm{q} \in \mathcal{S}} G_{\sigma_{\mathrm{s}}}(\|\mathbf{p}-\mathbf{q}\|) G_{\sigma_{\mathrm{r}}}\left(\left|I_{\mathrm{p}}-I_{\mathrm{q}}\right|\right)
$$

总结：

滤波器的应用：
1. 模板匹配：ssd可以用线性滤波器实现，对整体的亮度敏感
2. 高斯金字塔：从粗到精的搜索，多尺度检测
3. 拉普拉斯金字塔：更紧凑的图像表示方法，可以用来分解图像。
4. 压缩：JPEG，粗糙地量化高频信号。
5. 纹理的表示：使用filter bank
6. 去噪：中值滤波去除椒盐噪点，双边滤波保留边缘。